{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实践练习 – 预处理\n",
    "\n",
    "预处理的第一条规则是：**了解您的数据！**\n",
    "\n",
    "因此，您需要从多个方面和角度了解您的数据，将原始数据转换为已处理数据的状态，以供模型使用。\n",
    "\n",
    "建议使用 **TBLF** 方法：\n",
    "+ **尝试：**了解您的问题（在这里指的是了解您的数据）\n",
    "+ **是否损坏？：**什么损坏了？ （您是否发现数据出现问题）\n",
    "+ **了解：**为什么出现问题？ （数据存在哪些问题？ 如何解决这些问题？）\n",
    "+ **修复：**解决问题（怎么做才能为出现问题的数据提供可接受的解决方案？）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 业务场景\n",
    "您负责预处理公司要在新机器学习模型中使用的数据。该模型将基于各种来源（包括研究人员、 Web 抓取和出版商）的期刊/出版信息，来预测期刊的平均影响力。\n",
    "\n",
    "您已经收到了与要解决的业务问题相关的原始数据。您的任务是使用一些描述性统计信息来更好地理解数据。了解数据之后，您需要进行清理并重塑。您将在模型中使用处理过的最终数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学习目标\n",
    "1. 通过使用描述性统计信息分析数据，来了解业务场景和相应的数据集\n",
    "2. 使用可视化工具为此分析提供支持： \n",
    "    – 散点图，用于发现特征之间的相关性 \n",
    "    – 箱线图和直方图，用于了解数据分布\n",
    "3. 使用统计工具来支持以前的分析，例如使用相关矩阵来量化各种关系\n",
    "4. 根据分析结论，通过以下方法为模型准备处理后的数据集：\n",
    "    – 处理异常值 \n",
    "    – 处理缺失值\n",
    "    – 清理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集 \n",
    "数据来自多个来源，包括研究人员、Web 抓取和出版商。数据已经过处理，适合我们的预处理任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据架构\n",
    "一个有关期刊/出版商信息的数据集，包含预估的文章影响分数：\n",
    "+ journal_name：期刊名称\n",
    "'+ issn：唯一出版代码\n",
    "+ citation_count_sum：每份期刊的引用次数总和 \n",
    "+ paper_count_sum：每份期刊的论文数总和\n",
    "+ avg_cites_per_paper：每篇论文的平均引用次数\n",
    "+ ranking：为练习创建的人工标签（可能的值：A、B、C、D）\n",
    "+ proj_ai：预计的平均影响力"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先要加载文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_journals = pd.read_csv(\"estimated-article-influence-scores-Exerc2.csv\", sep=\";\")\n",
    "del df_journals[\"Unnamed: 0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 粗略浏览数据\n",
    "\n",
    "#### 了解\n",
    "您的数据中有多少特征？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of features: {}\".format(df_journals.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "您有多少样本？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of samples: {}\".format(df_journals.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 问题 1\n",
    "> #### 尝试\n",
    "> 打印前 10 行，看看数据是什么样的。对您的数据集应用 `head` 函数（[文档](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html?highlight=head#pandas.DataFrame.head）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在此处输入代码\n",
    "df_journals.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理缺失值\n",
    "#### 了解\n",
    "检查每列缺失多少个值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于数据集中存在缺失值的每个单元格，**isnull()** 命令会返回 **True**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_journals.isnull().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 是否损坏？\n",
    "这种可视化对于大型数据集来说是不切实际的。您可以尝试对每一列的所有行求和。由于上述所有值都是布尔值，因此，如果按列（特征）来求和，您将得到 **true** 值的数量，即每个特征的缺失值的数量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 问题 2\n",
    "> #### 修复\n",
    "> 如上所述，对您的数据集应用 **.isnull()** 函数，但将得到的结果与 **.sum()** 函数连接起来，以显示每个特征的缺失值的数量。<br/>\n",
    "\n",
    ">`isnull`（[文档](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isnull.html?highlight=isnull#pandas.DataFrame.isnull)）<br/>\n",
    ">`sum`（[文档](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sum.html?highlight=sum#pandas.DataFrame.sum)）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在此处输入代码\n",
    "df_journals.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 了解\n",
    "您观察到数据集中存在缺失值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "缺失值是一个非常重要的问题。大多数模型都无法很好地处理缺失值问题。\n",
    "\n",
    "您可以删除缺失值或替换这些值。这两种选择都有优缺点，具体取决于特定特征对您训练作业的重要性，以及您是否可以删除那些缺失值等。\n",
    "\n",
    "以下命令仅筛选具有 `any`（[文档](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.any.html?highlight=any#pandas.DataFrame.any)）缺失值的行。将显示前 10 行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_journals_null_data = df_journals[df_journals.isnull().any(axis=1)]\n",
    "df_journals_null_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理缺失值\n",
    "#### 修复\n",
    "假设您决定删除存在缺失值的行。\n",
    "\n",
    "您可以通过对数据集应用 `dropna` 函数（[文档](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html?highlight=dropna#pandas.DataFrame.dropna)）来删除缺失值。将结果保存在名为 *df_journals_no_miss** 的新数据集中。然后使用 `shape` 函数 ([文档](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.shape.html?highlight=shape#pandas.DataFrame.shape)) 来确认数据集已经删除了这些行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 了解\n",
    "剩下多少行？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_journals_no_miss = df_journals.dropna()\n",
    "df_journals_no_miss.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 了解\n",
    "确认您已删除所有缺失值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_journals_no_miss.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，假设您无法删除存在缺失值的行，可能是因为您不想缩小本来就很小的数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 替换数值\n",
    "#### 了解\n",
    "替换数值的一种方法是要考虑特征（列）值的平均值。以下命令可以计算数据集中所有数值特征的平均值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_count_sum_MEAN = df_journals[\"citation_count_sum\"].mean()\n",
    "paper_count_sum_MEAN = df_journals[\"paper_count_sum\"].mean()\n",
    "avg_cites_per_paper_MEAN = df_journals[\"avg_cites_per_paper\"].mean()\n",
    "proj_ai_MEAN = df_journals[\"proj_ai\"].mean()\n",
    "print(\"citation_count_sum_MEAN: {}\".format(citation_count_sum_MEAN))\n",
    "print(\"paper_count_sum_MEAN: {}\".format(paper_count_sum_MEAN))\n",
    "print(\"avg_cites_per_paper_MEAN: {}\".format(avg_cites_per_paper_MEAN))\n",
    "print(\"proj_ai_MEAN: {}\".format(proj_ai_MEAN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下命令将使用计算出的特征平均值来更新每个缺失值。\n",
    "\n",
    "**请注意：**`inplace` 子句（[文档](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html?highlight=fillna#pandas.DataFrame.fillna)）意味着更新已在原始数据集上生效，因此您无需将结果归到新数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_journals[\"citation_count_sum\"].fillna(citation_count_sum_MEAN, inplace=True)\n",
    "df_journals[\"paper_count_sum\"].fillna(paper_count_sum_MEAN, inplace=True)\n",
    "df_journals[\"avg_cites_per_paper\"].fillna(avg_cites_per_paper_MEAN, inplace=True)\n",
    "df_journals[\"proj_ai\"].fillna(proj_ai_MEAN, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 了解\n",
    "确认您已替换所有数值。接下来，您要处理分类值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_journals.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 替换分类值\n",
    "#### 了解\n",
    "对于分类值替换，一种常见的方法是使用最频繁出现的值（众数）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 尝试\n",
    "查看“排名”特征的可能值。\n",
    "\n",
    "Pandas 有一个很有趣的命令，可以显示分类的频率：`value_counts`（[文档](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html?highlight=value_counts#pandas.Series.value_counts)）。\n",
    "\n",
    "将此命令应用于数据集中的“排名”特征，以查看它的分类分布。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_journals[\"ranking\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，查看分类特征最频繁出现的值是什么。使用 `mode` 函数（[文档](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.mode.html?highlight=mode#pandas.DataFrame.mode)）。\n",
    "\n",
    "**请注意：** 您可以使用 `df_journals [“ ranking”]` 或 `df_journals.ranking` 访问该特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_journals.ranking.mode()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 了解\n",
    "该命令返回的最频繁出现的值（众数）是 **D**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用替换数值特征时所用的相同命令来替换最频繁出现的 **D**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_journals[\"ranking\"].fillna('D', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 了解\n",
    "现在，运行以下命令，查看是否还有空值。您现在应该只有 **False** 值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_journals.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 了解\n",
    "为了确保将缺失值替换为 D，**value_counts()** 命令应该会显示分类值 **D** 的新数量是原始值和空值数量的总和。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_journals[\"ranking\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 是否损坏？\n",
    "当标签之间的分布显示某些标签的频率比其他标签高得多时，就会出现不平衡的标签。这种情况并不适用于该数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数值的基本统计信息\n",
    "#### 了解分布\n",
    "##### 尝试\n",
    "计算每列的最小值、最大值、平均值、标准差以及 25% 和 75% 百分位数。使用 `describe` 命令（[文档](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html?highlight=describe#pandas.DataFrame.describe)）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_journals.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 问题 3\n",
    "绘制“avg_cites_per_paper”特征的分布图。使用 matplotlib 中的 `.plot.hist(bins=100)` 函数绘制每个特征的分布。\n",
    "\n",
    ">`hist`（[文档](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.hist.html?highlight=hist#matplotlib.pyplot.hist)）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在此处输入代码\n",
    "df_journals[\"avg_cites_per_paper\"].plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 箱线图\n",
    "箱线图非常适合发现异常值。我们使用箱线图进行了解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### 问题 4\n",
    ">#### 尝试\n",
    "> 现在，使用与绘制分布相同的方法，使用 `boxplot` 函数（[箱线图](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.boxplot.html?highlight=boxplot#matplotlib.pyplot.boxplot)）为数字特征“avg_cites_per_paper”绘制箱线图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在此处输入代码\n",
    "df_journals.boxplot([\"avg_cites_per_paper\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 了解 \n",
    "请注意，箱线图有助于发现异常值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 了解\n",
    "现在，我们使用一种更有趣的技术，通过百分位数来删除异常值。\n",
    "\n",
    "要打印数据集数值的百分位数，请使用 **.describe()** 命令。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_journals.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "您将使用 25%、50% 和 75% 百分位数（或四分位数）作为准则来删除异常值。\n",
    "\n",
    "对于每个特征，您将删除四分位数范围 (IQR) 之外的所有数据点，其中：\n",
    "\n",
    "$$IQR = 75\\% \\space quartile - 25\\% \\space quartile$$\n",
    "$$Lower \\space Threshold = 50\\% \\space percentile - 1.5 * IQR$$\n",
    "$$Upper \\space Threshold = 50\\% \\space percentile + 1.5 * IQR$$\n",
    "\n",
    "NumPy 软件包的 `percentile` 函数（[文档](https://docs.scipy.org/doc/numpy/reference/generated/numpy.percentile.html?highlight=percentile#numpy.percentile)）可以帮助您获取阈值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### 问题 5（可选）\n",
    ">#### 尝试\n",
    ">** 这个问题是可选的，不会计入评分**，但这是锻炼好奇心的好方法!\n",
    "\n",
    "> 使用 NumPy **percentile** 函数实施以下算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 修复\n",
    "对“citation_count_sum”特征执行以下操作：\n",
    "+ 使用上面的准则和 **percentile** 函数计算每个特征的阈值。\n",
    "+ 删除每个特征存在的超出此范围的异常值。\n",
    "+ 再次绘制箱线图以查看结果。\n",
    "+ 在删除前后使用 **shape** 命令查看删除了多少行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在此处输入代码\n",
    "print(\"Number of samples before: {}\".format(df_journals.shape[0]))\n",
    "# Save the quartiles\n",
    "citation_count_sum_25 = np.percentile(df_journals['citation_count_sum'], 25)\n",
    "citation_count_sum_50 = np.percentile(df_journals['citation_count_sum'], 50)\n",
    "citation_count_sum_75 = np.percentile(df_journals['citation_count_sum'], 75)\n",
    "\n",
    "# Calculate the thresholds\n",
    "IQR_citation_count_sum = citation_count_sum_75 - citation_count_sum_25\n",
    "Lower_Limit = citation_count_sum_50 - IQR_citation_count_sum * 1.5\n",
    "Upper_Limit = citation_count_sum_50 + IQR_citation_count_sum * 1.5\n",
    "\n",
    "# Remove the outliers\n",
    "df_journals = df_journals.loc[(df_journals['citation_count_sum'] > Lower_Limit) &amp;\n",
    "                              (df_journals['citation_count_sum'] &lt; Upper_Limit)]\n",
    "df_journals.boxplot([\"citation_count_sum\"])\n",
    "print(\"Number of samples after: {}\".format(df_journals.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 了解\n",
    "非常好！ 您已成功删除了异常值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 相关性：多变量统计\n",
    "#### 尝试\n",
    "对所有特征使用相关矩阵，为数据集中数值特征的每种组合绘制散点图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\", context=\"notebook\")\n",
    "sns.pairplot(df_journals[[\"citation_count_sum\", \"paper_count_sum\",\n",
    "                        \"avg_cites_per_paper\",\"proj_ai\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 是否损坏？\n",
    "有一个高度相关的特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 了解\n",
    "可以看到，proj_ai x avg_cites_per_paper 之间存在很强的非线性相关性，\n",
    "其他变量之间也存在一些相关性。\n",
    "但我们需要数字来决定是否删除一些高度相关的特征。\n",
    "所以，具有值的热图非常有帮助。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 问题 6\n",
    "> #### 尝试\n",
    "> 在 df_journal dataframe 中使用 `corr` 函数（[文档](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html?highlight=corr#pandas.DataFrame.corr)）来打印相关性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在此处输入代码\n",
    "corr = df_journals.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 学习\n",
    "请注意，对角线始终为 1（一），因为它表示针对自身的变量。\n",
    "\n",
    "##### 是否损坏？\n",
    "**proj_ai** 和 **avg_cites_per_paper** 变量高度相关（高于 99%）。\n",
    "\n",
    "#### 修复\n",
    "我们来尝试删除其中一个特征。您将从数据集中删除 **proj_ai** 特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_journals[\"proj_ai\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 了解\n",
    "现在，使用另一个很棒的工具，即 `heatmap`（[文档](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html?highlight=corr#pandas.DataFrame.corr)），在删除相关之后确认变量与目标之间的相关性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_journals.corr()\n",
    "ax = sns.heatmap(corr, annot=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "在本练习中，您练习了多种了解数据的方法。\n",
    "\n",
    "您从多个方面和角度了解了您的数据，将原始数据转换为已处理数据的状态，以供模型使用。\n",
    "\n",
    "您查看了一个简短的业务场景和相应的数据集，使用描述性统计信息对数据进行了分析，以便更好地了解数据。\n",
    "\n",
    "您使用了可视化工具（包括箱线图以及直方图）来支持此分析并了解数据的分布。在散点图的帮助下，您应用了多变量统计信息以发现特征之间的相关性。\n",
    "\n",
    "在**问题 1** 中，您发现了粗略浏览数据的重要性，查看了特征的数量以及样本的数量。您查看了第一行，看是否有什么需要注意的内容，例如缺失值。\n",
    "\n",
    "在**问题 2** 中，您学习并练习了如何决定是删除还是替换缺失值。在替换缺失值部分，您练习了如何处理数字替换或分类替换。\n",
    "\n",
    "**问题 3** 帮您了解了可以应用于您数据的基本统计信息。您练习了绘制特征的分布。\n",
    "\n",
    "在**问题 4** 中，您练习了另一个重要的数字特征图：箱线图。这是一个非常棒的工具，可用于发现异常值。\n",
    "\n",
    "**问题 5** 向您展示了一个有趣的指南，指导您使用百分位数删除异常值。您尝试实施了该算法。\n",
    "\n",
    "最后，在**问题 6** 中，您了解并练习了使用多变量技术（如相关矩阵和散点图）来发现特征之间的相关性，以及如何进行处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 做得好！\n",
    "现在，您已经清理了数据集，并已做好准备，可以进入建模步骤。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
