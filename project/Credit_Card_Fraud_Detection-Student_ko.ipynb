{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문제: 신용 카드 사기 예측 \n",
    "\n",
    "## 비즈니스 시나리오 소개\n",
    "여러분은 다국적 은행에서 일합니다. 지난 몇 달 동안 신용카드 사기를 당한 고객 수가 현격히 증가했습니다. 한 주요 뉴스 매체에서는 귀사 및 다른 은행이 겪고 있는 신용 카드 사기에 대한 기사를 실었습니다. \n",
    "\n",
    "이러한 상황에 대응으로, 회사에 더 큰 영향을 미치기 전에 기계 학습을 사용하여 사기성 신용카드 거래를 식별함으로써 이 문제의 일부를 해결해야 합니다. 여러분에게는 과거 신용 카드 트랜잭션 데이터 집합에 액세스할 수 있는 권한이 부여되었으며 이를 사용하여 트랜잭션이 사기인지 여부를 예측하도록 기계 학습 모형을 훈련할 수 있습니다. \n",
    "\n",
    "\n",
    "## 이 데이터 집합 소개\n",
    "이 데이터 집합에는 유럽인 카드 소지자가 2013년 9월에 신용 카드로 수행한 트랜잭션이 포함되어 있습니다. 이 데이터 집합은 2일 동안 발생한 트랜잭션을 제공하며 사기 트랜잭션과 합법적 트랜잭션의 예를 모두 포함합니다.\n",
    "\n",
    "### 특성\n",
    "데이터 집합에는 30개 이상의 수치형 특성이 포함되어 있으며, 대부분은 데이터의 개인 정보 보호 문제로 인해 주 성분 분석(PCA) 변환을 거쳤습니다. 주성분분석(PCA)으로 변환되지 않은 유일한 특성은 'Time' 및 'Amount'입니다. 'Time' 특성에는 데이터 집합에서 각 트랜잭션과 첫 번째 트랜잭션 사이에 경과된 시간(초)이 포함됩니다. 'Amount' 특성은 트랜잭션 금액입니다. 'Class'는 응답 또는 목표 변수이며, 사기의 경우'1'의 값을, 그렇지 않으면 '0'의 값을 갖습니다.\n",
    "\n",
    "특성: \n",
    "`V1, V2, ... V28`: PCA로 얻은 주 성분\n",
    "\n",
    "비 PCA 특성:\n",
    "- `Time`: 데이터 집합에서 각 트랜잭션과 첫 번째 트랜잭션 사이에 경과된 시간(초), $T_x - t_0$\n",
    "- `Amount`: 트랜잭션 금액. 이 특성은 예에 따라 비용에 민감한 학습에 사용 가능 \n",
    "- `Class`: `Fraud = 1` 및 `Not Fraud = 0`인 목표 변수\n",
    "\n",
    "### 데이터 집합 속성\n",
    "웹 사이트: https://www.openml.org/d/1597\n",
    "\n",
    "Twitter: https://twitter.com/dalpozz/status/645542397569593344\n",
    "\n",
    "작성자: Andrea Dal Pozzolo, Olivier Caelen 및 Gianluca Bontempi\n",
    "출처: 신용 카드 사기 탐지 – 2015년 6월 25일\n",
    "공식 인용: Andrea Dal Pozzolo, Olivier Caelen, Reid A. Johnson 및 Gianluca Bontempi. Calibrating Probability with Undersampling for Unbalanced Classification. 2015년 CIDM(Computational Intelligence and Data Mining)에 대한 IEEE 심포지엄.\n",
    "\n",
    "이 데이터 집합은 빅 데이터 마이닝 및 사기 탐지에 대한 ULB(Université Libre de Bruxelles)의 Machine Learning Group(mlg.ulb.ac.be)과 Worldline의 연구 협업 중에 수집 및 분석되었습니다. 관련 주제에 대한 현재 프로젝트와 과거 프로젝트에 대한 자세한 내용은 http://mlg.ulb.ac.be/BruFence 및 http://mlg.ulb.ac.be/ARTML에서 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1단계: 문제 공식화 및 데이터 수집\n",
    "\n",
    "이 시나리오의 비즈니스 문제와 달성하고자 하는 비즈니스 목표를 몇 문장으로 요약하여 아래에 작성하는 것으로 이 프로젝트를 시작하십시오. 팀에서 지향했으면 하는 비즈니스 지표를 포함합니다. 지표를 정의한 후 기계 학습 문제 기술서를 명확하게 작성합니다. 마지막으로, 이러한 문제에 해당하는 기계 학습의 유형에 대해 설명을 한 두 개 추가합니다.\n",
    "\n",
    "### <span style=\"color: blue;\">프로젝트 프레젠테이션: 프로젝트 프레젠테이션에 이러한 세부 정보에 대한 요약을 포함합니다.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 비즈니스 시나리오를 읽고 다음을 수행합니다.\n",
    "\n",
    "### 1. 기계 학습이 배포에 적합한 솔루션인지와 그 이유 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 답변 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 비즈니스 문제, 성공 지표 및 원하는 기계 학습 결과 공식화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 답변 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 해결하려는 기계 학습 문제의 유형 식별"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 답변 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 작업 중인 데이터의 적합성 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 답변 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 설정\n",
    "\n",
    "이제 어디에 에너지를 집중해야 할지 결정했으니, 문제 해결에 착수할 수 있도록 환경을 설정해 보겠습니다.\n",
    "\n",
    "**참고:** 이 노트북은 `ml.m4.xlarge` 노트북 인스턴스에서 생성 및 검정되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다양한 Python 라이브러리 가져오기\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imblearn 설치\n",
    "!pip uninstall scikit-learn -y\n",
    "!pip install imbalanced-learn==0.5.0\n",
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 집합 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일이 이미 원하는 경로에 있는지 아니면 다운로드해야 하는지 확인\n",
    "# 데이터 원본: https://www.openml.org/data/get_csv/1673544/phpKo8OWT\n",
    "import os\n",
    "import subprocess\n",
    "base_path = '/home/ec2-user/SageMaker/project/data/FraudDetection'\n",
    "file_path = '/fraud.csv'\n",
    "\n",
    "if not os.path.isfile(base_path + file_path):\n",
    "    subprocess.run(['mkdir', '-p', base_path])\n",
    "    subprocess.run(['aws', 's3', 'cp', \n",
    "                    's3://aws-tc-largeobjects/ILT-TF-200-MLDWTS/credit_card_project/', \n",
    "                    base_path,'--recursive'])\n",
    "else:\n",
    "    print('File already downloaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2단계: 데이터 전처리 및 시각화  \n",
    "이 데이터 전처리 단계에서는 데이터를 더 잘 이해할 수 있도록 데이터를 탐색하고 시각화할 수 있는 기회를 가져야 합니다. 먼저 필요한 라이브러리를 가져와서 데이터를 Pandas 데이터 프레임으로 읽어 들입니다. 그런 다음 데이터를 탐색합니다. 데이터 집합의 모양을 찾고 열과 작업 중인 열 유형(수치형, 범주형)을 탐색합니다. 특성에 대한 기본 통계를 수행하여 특성의 평균 및 범위를 파악하는 것이 좋습니다. 목표 열을 자세히 살펴보고 분포를 확인합니다.\n",
    "\n",
    "### 고려해야 할 구체적인 질문\n",
    "1. 특성에 대해 실행한 기본 통계에서 추론할 수 있는 것은 무엇인가요? \n",
    "\n",
    "2. 목표 클래스의 분포에서 추론할 수 있는 것은 무엇인가요?\n",
    "\n",
    "3. 데이터를 탐색하면서 추론한 것이 또 있나요?\n",
    "\n",
    "### <span style=\"color: blue;\">프로젝트 프레젠테이션: 이러한 질문과 기타 유사한 질문에 대한 답변을 요약하여 프로젝트 프레젠테이션에 포함시합니다.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV 데이터를 Pandas 데이터 프레임으로 읽어 들입니다. 기본 제공 Python 함수인 `read_csv`를 사용할 수 있습니다([설명서](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(<CODE>) # 여기에 코드 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 집합의 처음 5개 행을 인쇄하여 데이터 프레임을 확인합니다.  \n",
    "\n",
    "**힌트**: `<dataframe>.head()` 함수를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스에 부울 또는 숫자 0과 1 대신 이상한 문자열이 있으므로 이를 0과 1로 변환합니다. \n",
    "\n",
    "mapped_class = {\"'0'\": 0, \"'1'\": 1}\n",
    "df['Class'] = df['Class'].map(lambda x: mapped_class[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제대로 변환되었는지 확인\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**과제**: 데이터 집합의 모든 열을 검증하고 위에 설명한 대로 `V1-V28`, `Time`, `Amount` 및 `Class` 형태인지 확인합니다.  \n",
    "\n",
    "**힌트**: `<dataframe>.columns`를 사용하여 데이터 프레임의 열을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 답변 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**질문**: 열 유형 및 null 값에 대해 무엇을 알 수 있나요? 수치형 또는 범주형 열은 몇 개인가요? \n",
    "\n",
    "**힌트**: `info()` 함수를 사용하여 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**질문**: Pandas 라이브러리와 `Describe` 함수를 사용하여 기본 통계를 수행합니다. `amount` 특성의 평균 및 표준 편차는 어떻게 되나요? 이러한 수치에서 무엇을 추론할 수 있나요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 답변 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**질문**: 사기인 레코드의 `amount`에 대한 평균, 표준 편차 및 최대값은 얼마인가요?  \n",
    "\n",
    "**힌트**: 데이터 프레임에서 기본 제공하는 `mean()`, `std()` 및 `max()` 함수를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fraud Statistics\")\n",
    "\n",
    "avg_amt = # 여기에 코드 입력\n",
    "std_dev = # 여기에 코드 입력\n",
    "max_amt = # 여기에 코드 입력\n",
    "\n",
    "print(f\"The average amount is {avg_amt}\")\n",
    "print(f\"The std deviation for amount is {std_dev}\")\n",
    "print(f\"The max amount is {max_amt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 답변 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 목표 변수인 `Class`를 살펴봅니다. 먼저 이 변수의 분포가 어떻게 되는지 확인할 수 있습니다.\n",
    " \n",
    "**질문**: Class의 분포는 어떻게 되나요?  \n",
    "\n",
    "**힌트**: `<dataframe>['column_name'].value_counts()`를 사용하여 분포를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 답변 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**질문**: 이 클래스의 분포에서 추론할 수 있는 것은 무엇인가요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 답변 입력:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**질문**: 0인 Class 대 전체 레코드 수의 비율은 어떻게 되나요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 시각화\n",
    "위에서 시각화를 수행하지 않은 경우 아래 공간을 사용하여 일부 데이터를 추가로 시각화할 수 있습니다. 특히 `Amount` 및 `Time`과 같은 특성의 분포를 살펴보고 데이터 집합에서 특성 간 선형 상관 관계를 계산합니다. \n",
    "\n",
    "### 고려해야 할 구체적인 질문\n",
    "1. `Amount` 및 `Time`과 같은 특성의 분포를 살펴보니 이러한 특성이 모형에 어느 정도 도움이 될까요? 이러한 분포에서 데이터를 더 잘 이해하는 데 도움이 되도록 추론할 수 있는 것이 있나요?\n",
    "\n",
    "2. 사기로 레이블이 지정된 데이터만 볼 때는 `Amount` 및 `Time`과 같은 특성의 분포가 다른가요?\n",
    "\n",
    "3. 데이터 집합에 강력한 상관 관계가 있는 특성이 있습니까? 그렇다면 다음 단계는 무엇인가요?\n",
    "\n",
    "아래 셀을 사용하여 데이터를 시각화하고 이러한 질문과 관심을 가질만한 다른 질문에 답하십시오. 필요에 따라 셀을 삽입하고 삭제합니다.\n",
    "\n",
    "### <span style=\"color: blue;\">프로젝트 프레젠테이션: 이러한 질문과 유사한 질문에 대한 답변을 요약하여 프로젝트 프레젠테이션에 포함합니다.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 단순 산점도부터 시작합니다. Plot V1 vs. V2. 산점도 표시에 대한 자세한 내용은 [Matplotlib 설명서](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.plot.html)를 참조하십시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(<CODE>, <CODE>, '.') # 여기에 코드 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일부 특성의 분포를 살펴봅니다. '`sns.distplot()`을 사용하여 `Amount` 및 `Time`과 같은 개별 특성의 분포를 찾습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(<CODE>) # 여기에 코드 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**질문**: `Time` 특성이 어떤 식으로든 도움이 될까요? 분포를 다시 살펴보겠습니다. 산점도에서 무엇을 추론할 수 있나요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 답변 입력:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "히스토그램과 KDE(커널 밀도 추정)를 표시합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df[df['Class'] == 1]['Time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**질문**: `Amount` 열의 사기 사례에서는 이 분포가 어떤 모습인가요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(<CODE>)# 여기에 코드 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 `pairplot`이라는 Seaborn 함수를 사용하는 분포를 살펴보겠습니다. `pairplot`은 산점도 그리드를 생성하며 여기에서 데이터 집합의 각 특성이 X축으로 한 번, Y축으로 한 번 사용됩니다. 이 그리드의 대각선은 해당 특징에 대한 데이터의 분포를 보여줍니다. \n",
    "\n",
    "`V1`, `V2`, `V2`, `V4` 및 `Class` pairplot을 살펴봅니다. 플롯에서 무엇을 볼 수 있나요? 이러한 특성에서 사기와 사기가 아닌 것을 구분할 수 있나요?  \n",
    "\n",
    "**힌트**: `V1`, `V2`, `V4` 및 `Class` 열로 새로운 데이터 프레임을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_df = # 여기에 코드 입력\n",
    "sns.pairplot(new_df, hue=\"Class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용한 특성의 하위 집합에 대해서는 사기와 사기가 아닌 것을 구분할 수 있는 방법이 있지만, 한 가지 특성을 기준으로 이를 구분하기는 쉽지 않습니다.\n",
    "\n",
    "이제 이러한 특성이 서로 어떻게 상호 작용하는지 살펴보겠습니다. Pandas `<dataframe>.corr()` 함수를 사용하여 데이터 집합의 모든 특성 간 선형 상관 관계를 계산합니다. 언제나 상관 관계를 시각화하는 것이 더 쉽습니다. `annot` 플래그가 `True`로 설정된 Seaborn 열 지도(`sns.heatmap`) 함수를 사용하여 상관 관계를 표시합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (25,15))\n",
    "correlation_matrix = # 여기에 코드 입력\n",
    "sns.heatmap(correlation_matrix, annot=True,fmt=\".2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**질문**: 상관 특성의 경우 모형을 훈련하기 전에 해당 특성 중 하나를 제거해야 합니다. 제거할 수 있는 특성이 있나요?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 답변 입력:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> 실습 2 종료 </span>\n",
    "\n",
    "프로젝트 파일을 로컬 컴퓨터에 저장합니다. 방법은 다음과 같습니다.\n",
    "\n",
    "1. 페이지 상단에 있는 **파일** 메뉴를 클릭합니다. \n",
    "\n",
    "1. **다운로드**를 선택하고 **Notebook(.ipynb)**을 클릭합니다.  \n",
    "\n",
    "그러면 현재 노트북이 컴퓨터의 기본 다운로드 폴더로 다운로드됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3단계: 모형 훈련 및 평가\n",
    "\n",
    "DataFrame에서 기계 학습 알고리즘이 사용할 수 있는 형식으로 데이터 집합을 변환할 때 포함해야 하는 몇 가지 예비 단계가 있습니다. Amazon SageMaker의 경우 다음 단계를 수행해야 합니다.\n",
    "\n",
    "1. `sklearn.model_selection.train_test_split`을 사용하여 데이터를 `train_data`, `validation_data` 및 `test_data`로 분할합니다.    \n",
    "2. 데이터 집합을 Amazon SageMaker 훈련 작업에서 사용할 수 있는 적절한 파일 형식으로 변환합니다. CSV 파일 또는 레코드 protobuf로 변환하면 됩니다. 자세한 내용은 [훈련을 위한 공통 데이터 형식](https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-training.html) 페이지를 참조하십시오.    \n",
    "3. 데이터를 Amazon S3 버킷에 업로드합니다.\n",
    "\n",
    "다음 셀을 사용하여 이러한 단계를 완료합니다. 필요에 따라 셀을 삽입하고 삭제합니다.\n",
    "\n",
    "### <span style=\"color: blue;\">프로젝트 프레젠테이션: 이 단계에서 내린 주요 의사 결정을 프로젝트 프레젠테이션에 기록해 둡니다.</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "– 훈련 및 모형 데이터에 사용할 Amazon Simple Storage Service(S3) 버킷 및 접두사(?). 노트북 인스턴스, 훈련 및 호스팅과 동일한 리전 내에 있어야 합니다.\n",
    "– 데이터에 대한 훈련 및 호스팅 액세스 권한을 부여하는 데 사용되는 AWS Identity and Access Management(IAM) 역할 [Amazon 리소스 이름(ARN)](https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html). 이러한 항목을 생성 방법은 설명서를 참조하십시오.\n",
    "\n",
    "**참고:** 노트북 인스턴스, 훈련 및/또는 호스팅에 둘 이상의 역할이 필요한 경우 `get_execution_role()` 호출을 적절한 전체 IAM 역할 ARN 문자열로 대체하십시오.\n",
    "\n",
    "***`<LabBucketName>`**을(를) 실습 계정에 제공된 리소스 이름으로 바꿉니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker.amazon.amazon_estimator import RecordSet\n",
    "\n",
    "# Amazon SageMaker 세션 인스턴스화\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "# Amazon SageMaker 역할 가져오기 \n",
    "role = get_execution_role()\n",
    "\n",
    "# 버킷 이름\n",
    "bucket = <LabBucketName>\n",
    "\n",
    "# 선형 학습자 알고리즘이 포함된 컨테이너의 이미지 URI 가져오기\n",
    "container = get_image_uri(boto3.Session().region_name, 'linear-learner')\n",
    "\n",
    "print(f'Session {sess}')\n",
    "print(f'The role is {role}')\n",
    "print(f'The container is {role} in the {boto3.Session().region_name} region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_training_sets(data):\n",
    "    \"\"\"\n",
    "    데이터 프레임을 훈련, 검증 및 검정으로 변환\n",
    "    params:\n",
    "        data: 분할할 데이터 집합이 있는 데이터 프레임\n",
    "    Returns:\n",
    "        train_features: 훈련 특성 데이터 집합\n",
    "        test_features: 검정 특성 데이터 집합 \n",
    "        train_labels: 훈련 데이터 집합의 레이블\n",
    "        test_labels: 검정 데이터 집합의 레이블\n",
    "        val_features: 검증 특성 데이터 집합\n",
    "        val_labels: 검증 데이터 집합의 레이블\n",
    "    \"\"\"\n",
    "    # 데이터 프레임에서 목표 변수를 추출하고 유형을 float32로 변환\n",
    "    ys = np.array(<CODE>).astype(\"float32\") # 여기에 코드 입력\n",
    "    \n",
    "    # 목표 열을 비롯하여 원하지 않는 모든 열 삭제\n",
    "    drop_list = # 여기에 코드 입력\n",
    "    \n",
    "    # drop_list에서 열을 삭제하고 데이터를 유형 float32의 NumPy 배열로 변환\n",
    "    xs = np.array(data.drop(<CODE>, axis=1)).astype(\"float32\")# 여기에 코드 입력\n",
    "    \n",
    "    np.random.seed(0)\n",
    "\n",
    "    # sklearn 함수인 train_test_split을 사용하여 데이터 집합을 훈련 80%와 검정 20% 비율로 분할합니다.\n",
    "    # 예: train_test_split(x, y, test_size=0.3)\n",
    "    train_features, test_features, train_labels, test_labels = # 여기에 코드 입력\n",
    "    \n",
    "    # sklearn 함수를 다시 사용하여 검정 데이터 집합을 검증 50%와 검정 50%로 분할\n",
    "    val_features, test_features, val_labels, test_labels = # 여기에 코드 입력\n",
    "    \n",
    "    return train_features, test_features, train_labels, test_labels, val_features, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 함수를 사용하여 데이터 집합 생성\n",
    "train_features, test_features, train_labels, test_labels, val_features, val_labels = create_training_sets(df)\n",
    "\n",
    "print(f\"Length of train_features is: {<CODE>}\")\n",
    "print(f\"Length of train_labels is: {<CODE>}\")\n",
    "print(f\"Length of val_features is: {<CODE>}\")\n",
    "print(f\"Length of val_labels is: {<CODE>}\")\n",
    "print(f\"Length of test_features is: {<CODE>}\")\n",
    "print(f\"Length of test_labels is: {<CODE>}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 샘플 출력\n",
    "```\n",
    "Length of train_features is: (227845, 29)  \n",
    "Length of train_labels is: (227845,)  \n",
    "Length of val_features is: (28481, 29)  \n",
    "Length of val_labels is: (28481,)  \n",
    "Length of test_features is: (28481, 29)  \n",
    "Length of test_labels is: (28481,)  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모형 훈련\n",
    "\n",
    "먼저 ml.m4.xlarge 인스턴스 1개로 `predictor_type='binary_classifier'` 파라미터를 사용하여  LinearLearner 추정기를 인스턴스화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.amazon.amazon_estimator import RecordSet\n",
    "import boto3\n",
    "\n",
    "# LinearLearner 추정기 객체 인스턴스화\n",
    "num_classes = # 여기에 코드 입력\n",
    "\n",
    "# ml.m4.xlarge 인스턴스 1개로 LinearLearner 추정기 'binary classifier' 객체 인스턴스화\n",
    "linear = sagemaker.LinearLearner(role=sagemaker.get_execution_role(),\n",
    "                                               train_instance_count=<CODE>,\n",
    "                                               train_instance_type=<CODE>,\n",
    "                                               predictor_type=<CODE>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 샘플 코드\n",
    "```\n",
    "num_classes = len(pd.unique(train_labels))\n",
    "linear = sagemaker.LinearLearner(role=sagemaker.get_execution_role(),\n",
    "                                              train_instance_count=1,\n",
    "                                              train_instance_type='ml.m4.xlarge',\n",
    "                                              predictor_type='binary_classifier',\n",
    "                                             )\n",
    "                                              \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "선형 학습자는 protobuf 또는 CSV 콘텐츠 유형의 훈련 데이터를 수용하고 protobuf, CSV 또는 JSON 콘텐츠 유형의 추론 요청을 수용합니다. 훈련 데이터에는 특성과 ground-truth 레이블이 있으며, 추론 요청의 데이터에는 특성만 있습니다. 프로덕션 파이프라인에서는 데이터를 Amazon SageMaker protobuf 형식으로 변환하여 Amazon S3에 저장하는 것이 좋습니다. 하지만 빠르게 시작하고 실행할 수 있도록 AWS에서는 데이터 집합이 로컬 메모리에 적합할 정도로 작을 때 쉽게 변환하고 업로드할 수 있는 편리한 메서드인 `record_set`을 제공합니다. 이 메서드는 이미 가지고 있는 것과 같은 NumPy 배열을 수락하므로 여기에서 사용해 보겠습니다. '`RecordSet` 객체는 데이터의 임시 Amazon S3 위치를 추적합니다. `estimator.record_set` 함수를 사용하여 train, validation 및 test 레코드를 생성합니다. 그런 다음 `estimator.fit` 함수를 사용하여 훈련 작업을 시작합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### train, val, test 레코드 생성\n",
    "train_records = linear.record_set(<CODE>,<CODE>, channel='train')# 여기에 코드 입력\n",
    "val_records = linear.record_set(<CODE>,<CODE>, channel='validation')# 여기에 코드 입력\n",
    "test_records = linear.record_set(<CODE>,<CODE>, channel='test')# 여기에 코드 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 방금 업로드한 데이터 집합으로 모형을 훈련하겠습니다.\n",
    "\n",
    "### 샘플 코드\n",
    "```\n",
    "linear.fit([train_records,val_records,test_records], wait=True, logs='All')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 분류자 피팅\n",
    "# 여기에 코드 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모형 평가\n",
    "이 섹션에서는 훈련된 모형을 평가합니다. 먼저 `estimator.deploy` 함수를 `initial_instance_count= 1` 및 `instance_type= 'ml.m4.xlarge'`와 함께 사용하여 Amazon SageMaker에 모형을 배포합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_predictor = linear.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 호스팅된 엔드포인트가 실행되고 있으므로 http POST 요청을 통해 모형에서 손쉽게 실시간 예측을 수행할 수 있습니다. 하지만 먼저 `test_features` NumPy 배열을 엔드포인트 뒤의 모형에 전달하기 위해 직렬 변환 및 역직렬 변환을 설정해야 합니다. 또한 모형의 혼동 행렬을 계산하여 검정 데이터에서 어떤 성능을 발휘했는지 시각적으로 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score, recall_score\n",
    "#from sagemaker.predictor import csv_serializer, json_deserializer, numpy_deserializer\n",
    "#from sagemaker.predictor import csv_deserializer\n",
    "\n",
    "def predict_batches(model, features, labels, split=200):\n",
    "    \"\"\"\n",
    "    분할에서 지정한 대로 배치로 데이터 포인트를 예측합니다. \n",
    "    데이터는 <split>개의 파트로 분할되고 model.predict가 \n",
    "    각 파트에서 호출됨\n",
    "    Arguments:\n",
    "        model: predict 함수를 호출하는 데 사용할 모형\n",
    "        features: 예측할 데이터 집합\n",
    "        labels: 레코드의 참 값\n",
    "        split: 데이터를 분할할 파트 수\n",
    "    Returns:\n",
    "        없음\n",
    "    \"\"\"\n",
    "\n",
    "    split_array = np.array_split(features, split)\n",
    "    predictions = []\n",
    "    for array in split_array:\n",
    "        predictions += model.predict(array).label\n",
    "\n",
    "    # preds = np.array([예측에서 p에 대한 p['predicted_label'])\n",
    "    preds = [i.label['predicted_label'].float32_tensor.values[0] for i in predictions]\n",
    "    \n",
    "    # 정확도 계산\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    \n",
    "    # 정밀도 계산\n",
    "    precision = precision_score(labels, preds)\n",
    "    print(f'Precision: {precision}')\n",
    "    \n",
    "    # 재현율 계산\n",
    "    recall = recall_score(labels, preds)\n",
    "    print(f'Recall: {recall}')\n",
    "    \n",
    "    confusion_matrix = pd.crosstab(index=labels, columns=np.round(preds), rownames=['True'], colnames=['predictions']).astype(int)\n",
    "    plt.figure(figsize = (5,5))\n",
    "    sns.heatmap(confusion_matrix, annot=True, fmt='.2f', cmap=\"YlGnBu\").set_title('Confusion Matrix') \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 엔드포인트가 'InService' 상태이므로 검정 집합에서 모형의 성능이 어떤지 평가합니다. 검정 집합에서의 성능을 훈련 집합에서의 성능과 비교합니다. \n",
    "\n",
    "### 고려해야 할 주요 질문:\n",
    "1. 훈련 집합과 비교하여 검정 집합에서의 모형 성능이 어떤가요? 이 비교에서 무엇을 추론할 수 있나요? \n",
    "\n",
    "2. 정확도, 정밀도, 재현율과 같은 지표의 결과 간에 분명한 차이가 있나요? 만약 그렇다면, 이러한 차이가 나타나는 이유는 무엇일까요? \n",
    "\n",
    "3. 비즈니스 상황과 목표를 고려래 볼 때 여기서 고려해야 할 가장 중요한 지표는 무엇일까요? 그 이유는 무엇일까요?\n",
    "\n",
    "4. 가장 중요하다고 생각하는 지표의 결과가 비즈니스 관점에서 필요한 결과로도 충분한가요? 그렇지 않다면, 다음 반복(다음에 나오는 특성 엔지니어링 섹션)에서 무엇을 변경할 수 있을까요? \n",
    "\n",
    "아래 셀을 사용하여 이러한 질문과 기타 질문에 답하십시오. 필요에 따라 셀을 삽입하고 삭제합니다.\n",
    "\n",
    "### <span style=\"color: blue;\">프로젝트 프레젠테이션: 이러한 질문과 이 섹션에서 대답할 수 있는 유사한 질문에 대한 답변을 프로젝트 프레젠테이션에 기록합니다. 주요 세부 정보와 결정한 내용을 프로젝트 프레젠테이션에 기록합니다.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_batches(linear_predictor, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검정 집합과 마찬가지로 훈련 집합에 대한 지표도 살펴볼 수 있습니다. 위의 로그에도 이러한 지표가 표시된다는 점을 기억하십시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict_batches(linear_predictor, train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론 엔드포인트 삭제\n",
    "sagemaker.Session().delete_endpoint(linear_predictor.endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <span style=\"color:red\"> 실습 3 종료 </span>\n",
    "\n",
    "프로젝트 파일을 로컬 컴퓨터에 저장합니다. 방법은 다음과 같습니다.\n",
    "\n",
    "1. 페이지 상단에 있는 **파일** 메뉴를 클릭합니다. \n",
    "\n",
    "1. **다운로드**를 선택하고 **Notebook(.ipynb)**을 클릭합니다.  \n",
    "\n",
    "그러면 현재 노트북이 컴퓨터의 기본 다운로드 폴더로 다운로드됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 반복 II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4단계: 특성 엔지니어링\n",
    "\n",
    "이제 모형을 훈련하고 평가하는 과정을 한 번 반복했습니다. 처음 모형을 사용해 도달한 결과로는 비즈니스 문제를 해결하는 데 충분하지 않을 수 있다는 점을 감안할 때 모형 성능을 개선하기 위해 데이터에 대해 변경할 수 있는 사항은 무엇인가요?\n",
    "\n",
    "### 고려해야 할 주요 질문:\n",
    "1. 두 개의 주요 클래스(사기 및 사기가 아님)의 균형이 모형 성능에 어떤 영향을 미치나요?\n",
    "2. 데이터 집합의 균형이 특성 간 상관 관계에 영향을 미치나요?\n",
    "3. 이 단계에서 모형 성능에 긍정적인 영향을 미칠 수 있는 특성 축소 기법이 있나요? \n",
    "4. 약간의 특성 엔지니어링을 수행한 후 첫 번째 반복과 비교하여 모형 성능이 어떤가요?\n",
    "\n",
    "아래 셀을 사용하여 모형 성능을 향상할 수 있다고 생각되는 특정 특성 엔지니어링 기법(위의 질문에 따라)을 수행합니다. 필요에 따라 셀을 삽입하고 삭제합니다.\n",
    "\n",
    "### <span style=\"color: blue;\">프로젝트 프레젠테이션: 이 섹션에서 사용하는 주요 결정 사항과 기법은 물론 모형을 다시 평가한 후 얻은 새로운 성능 지표를 프로젝트 프레젠테이션에 기록합니다.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시작하기 전에 왜 정확도 및 재현율은 약 80%인데 정확도는 99%인지 생각해 보십시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 답변 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정확도는 모형이 올바른 답을 제시한 예제의 수로 계산됩니다. 그러나 대부분의 예제는 실제로 부정입니다. 따라서 이 매우 불균형한 데이터 집합에서 모든 예제를 0으로 예측하더라도 여전히 약 99.827%의 정확도를 얻을 수 있습니다. 데이터 집합이 불균형하면 알고리즘 성능에 일부 문제가 발생할 수 있습니다. 따라서 모형을 훈련하기 전에 데이터의 불균형을 처리하는 것이 유용합니다.\n",
    "\n",
    "**질문**: 데이터 집합 불균형 문제는 어떻게 해결하나요?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 답변 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**질문**: 데이터 집합의 형태를 다시 인쇄합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Length of train_features is: {train_features.shape}\")\n",
    "print(f\"Length of train_labels is: {train_labels.shape}\")\n",
    "print(f\"Length of val_features is: {val_features.shape}\")\n",
    "print(f\"Length of val_labels is: {val_labels.shape}\")\n",
    "print(f\"Length of test_features is: {test_features.shape}\")\n",
    "print(f\"Length of test_labels is: {test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sns.countplot`을 사용하여 데이터 집합의 원래 분포를 표시합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df['Class'])\n",
    "plt.title('Original Distribution of the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'`train_features`를 다시 DataFrame으로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(<CODE>, columns = df.columns.drop(['Time','Class'])) # 여기에 코드 입력\n",
    "df_train['Target'] = # 여기에 코드 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "불균형한 데이터 집합을 처리하는 방법은 크게 두 가지가 있습니다.\n",
    "\n",
    "- 더 많은 긍정 표본을 추가하는 과잉표본(oversample)\n",
    "    - 랜덤 과잉표본(oversample)\n",
    "    - [SMOTE(합성소수 과잉표본 기법)](https://arxiv.org/abs/1106.1813)\n",
    "- 부정 표본을 줄이기 위한 과소표본(undersample)\n",
    "    - 랜덤 과소표본\n",
    "    - 군집화 기법을 사용하여 중심 생성\n",
    "\n",
    "데이터 집합 표집에는 `Imbalanced-learn`이라는 라이브러리를 사용할 수 있습니다. `Imbalanced-learn`은 클래스 간 불균형이 심한 데이터 집합에 일반적으로 사용되는 여러 가지 재표집 기법을 제공하는 Python 패키지입니다. scikit-learn과 호환되며 scikit-learn-contrib 프로젝트의 일부입니다. 자세한 내용은 [imbalanced-learn API 설명서](https://imbalanced-learn.org/stable/introduction.html)를 참조하십시오. \n",
    "\n",
    "먼저 이 예제에 대해 과소표본을 선택합니다. 균형 잡힌 데이터 집합을 생성하려면 다음을 수행합니다.\n",
    "\n",
    "1. 모두 긍정 예제로 이루어진 새로운 DataFrame `fraud_df`를 생성합니다.\n",
    "2. 또 다른 DataFrame `non_fraud_df`를 생성하고 `fraud_df` DataFrame 및 `random_state=235`.와 동일한 수로 `dataframe.sample`을 사용합니다.\n",
    "3. 두 DataFrame을 모두 새로운 DataFrame `balanced_df`로 연결합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target == 1인 df_train 데이터 프레임에서 행을 선택합니다.\n",
    "fraud_df = # Target == 1\n",
    "\n",
    "# Target == 0인 df_train 데이터 프레임에서 행을 선택합니다.\n",
    "non_fraud_df = # Target == 0\n",
    "\n",
    "balanced_df = pd.concat([fraud_df, non_fraud_df], ignore_index=True, sort=False)\n",
    "\n",
    "balanced_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sns.countplot()`을 사용하여 분포와 형태를 다시 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드 입력\n",
    "plt.title('Original Distribution of the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련을 살펴보기 전에 데이터 집합에 t-분포 확률적 임베딩(t-SNE)과 같은 특성 축소 기법을 사용할 경우 어떤 일이 발생할지 살펴봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "X_embedded = TSNE(n_components=2).fit_transform(<CODE>)\n",
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.scatter(X_embedded[:,0], X_embedded[:,1], \n",
    "            c = balanced_df['Target'],\n",
    "            s = 1,\n",
    "            cmap = ListedColormap(['Red', 'Blue']),\n",
    "            linewidths=1)\n",
    "\n",
    "plt.title('Red: 0 , Blue: 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**질문**: t-SNE는 사기와 사기가 아님을 구분하는 데 도움이 되나요?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 답변 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 새로운 데이터가 있으므로 전과 후의 상관 행렬이 어떻게 다른지 비교합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상관 행렬에서 하위 표본을 사용해야 합니다.\n",
    "\n",
    "plt.figure(figsize = (20,10))\n",
    "\n",
    "# 원래 데이터 집합을 사용하여 특성 간 상관 관계 찾기\n",
    "correlation_matrix_before = # 여기에 코드 입력\n",
    "sns.heatmap(correlation_matrix_before, annot=True,fmt=\".2f\")\n",
    "\n",
    "plt.figure(figsize = (20,10))\n",
    "\n",
    "# 원래 데이터 집합을 사용하여 특성 간 상관 관계 찾기\n",
    "correlation_matrix_after = # 여기에 코드 입력\n",
    "sns.heatmap(correlation_matrix_after, annot=True,fmt=\".2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**질문**: 두 상관 행렬을 보고 추론할 수 있는 것은 무엇인가요? 차이가 있는 경우 차이가 있는 이유를 분석할 수 있나요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 답변 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**질문**: 상관된 데이터 때문에 열을 삭제하시겠어요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 답변 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일부 상관 관계가 있기 때문에 0.9보다 큰 상관 관계를 가진 데이터를 제거해 보겠습니다. 다음 셀을 실행하여 `V17` 및 `V18` 열을 삭제합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "balanced_df_drop = balanced_df.drop(columns=['V17','V18'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 균형 잡힌 새로운 데이터 집합을 사용하여 훈련, 배포 및 평가할 차례입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 샘플 코드\n",
    "\n",
    "```\n",
    "# LinearLearner 추정기 객체 인스턴스화\n",
    "num_classes = len(pd.unique(train_labels))\n",
    "linear_estimator_balanced = sagemaker.LinearLearner(role=sagemaker.get_execution_role(),\n",
    "                                               train_instance_count=1,\n",
    "                                               train_instance_type='ml.m4.xlarge',\n",
    "                                               predictor_type='binary_classifier')\n",
    "\n",
    "\n",
    "train_records_bal = linear_estimator_balanced.record_set(balanced_df.drop(['Target'], axis=1).as_matrix(), \n",
    "                                                balanced_df['Target'].as_matrix(), \n",
    "                                                channel='train')\n",
    "val_records_bal = linear_estimator_balanced.record_set(val_features, val_labels, channel='validation')\n",
    "test_records_bal = linear_estimator_balanced.record_set(test_features, test_labels, channel='test')\n",
    "\n",
    "linear_estimator_balanced.fit([train_records_bal, val_records_bal, test_records_bal])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분포를 구성하는 예제 수를 줄이니 재현율이 증가하기 보다는 감소했습니다. 높은 재현율이 필요하므로 다른 전략을 시도해 보겠습니다.\n",
    "\n",
    "SMOTE를 사용하여 긍정 예제의 수를 늘립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE \n",
    "\n",
    "# 원본 데이터 집합에서 필요 없는 열 삭제\n",
    "X = # 여기에 코드 입력\n",
    "\n",
    "# 클래스 특성을 레이블로 사용\n",
    "y = # 여기에 코드 입력\n",
    "\n",
    "sm = SMOTE(random_state=35)\n",
    "X_res, y_res = sm.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**선택 사항**: 새로운 데이터 집합을 Pandas DataFrame으로 변환하고 데이터의 형태와 분포를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_df = pd.DataFrame(<CODE>, # 여기에 코드 입력\n",
    "                        columns = df.drop(['Class', 'Time'], axis=1).columns) \n",
    "smote_df['Class'] = # 여기에 코드 입력\n",
    "smote_df['Time'] = df['Time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "새로운 훈련, 검정 및 검증 데이터 집합을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels, val_features, val_labels = create_training_sets(<CODE>))# 여기에 코드 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "새로운 데이터 집합을 사용하여 모형을 훈련합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(pd.unique(train_labels))\n",
    "linear_estimator_smote = sagemaker.LinearLearner(role=sagemaker.get_execution_role(),\n",
    "                                               train_instance_count=1,\n",
    "                                               train_instance_type='ml.m4.xlarge',\n",
    "                                               predictor_type='binary_classifier')\n",
    "\n",
    "\n",
    "train_records_smote = linear_estimator_smote.record_set(train_features, train_labels, channel='train')\n",
    "val_records_smote = linear_estimator_smote.record_set(val_features, val_labels, channel='validation')\n",
    "test_records_smote = linear_estimator_smote.record_set(test_features, test_labels, channel='test')\n",
    "\n",
    "linear_estimator_smote.fit([train_records_smote, val_records_smote, test_records_smote])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**질문**: 훈련 작업 평가에서 무엇을 추론할 수 있나요?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 답변 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터 최적화\n",
    "모형 튜닝 단계에는 하이퍼파라미터 최적화도 포함됩니다. 이 섹션에서는 하이퍼파라미터를 튜닝하여 튜닝이 모형 성능을 향상하는 정도를 확인할 수 있는 기회를 제공합니다. 다음 템플릿 코드를 사용하면 Amazon SageMaker 하이퍼파라미터 튜닝 작업을 시작하고 평가 지표를 볼 수 있습니다. 다음 질문을 사용하면 섹션 나머지 부분을 진행하는 데 도움이 됩니다.\n",
    "\n",
    "### 고려해야 할 주요 질문:\n",
    "1. 튜닝 작업 시간이 증가함에 따라 선택한 목표 지표의 결과는 어떻게 변하나요? 구현되는 다양한 목표 지표와 시간 간의 관계는 어떻게 되나요? \n",
    "2. 목표 지표와 개별 하이퍼파라미터 간의 상관 관계는 어떻게 되나요? 목표 지표와 강력한 상관 관계가 있는 하이퍼파라미터가 있나요? 그렇다면 이러한 강력한 상관 관계를 활용하려면 어떻게 해야 할까요?\n",
    "3. 하이퍼파라미터 튜닝 후 모형의 성능을 분석합니다. 현재 성능으로 비즈니스 문제를 해결할 수 있나요?\n",
    "\n",
    "### <span style=\"color: blue;\">프로젝트 프레젠테이션: 이 섹션에서 사용하는 주요 결정 사항과 기법은 물론 모형을 다시 평가한 후 얻은 새로운 성능 지표를 프로젝트 프레젠테이션에 기록합니다.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "hyperparameter_ranges = {'wd': ContinuousParameter(<CODE>, <CODE>),\n",
    "                        'l1': ContinuousParameter(<CODE>, <CODE>),\n",
    "                        'learning_rate': ContinuousParameter(<CODE>, <CODE>)\n",
    "                        }\n",
    "\n",
    "objective_metric_name = <CODE>\n",
    "\n",
    "tuner = HyperparameterTuner(<ENTER your estimator name>,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            max_jobs=10,\n",
    "                            max_parallel_jobs=3)\n",
    "\n",
    "tuner.fit([<CODE>], include_cls_metadata=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터 튜닝 작업 진행 상황 추적\n",
    "\n",
    "튜닝 작업을 시작한 후 `describe_tuning_job` API를 호출하여 진행 상황을 확인할 수 있습니다. `describe-tuning-job`의 출력은 튜닝 작업의 현재 상태에 대한 정보가 포함된 JSON 객체입니다. `list_training_jobs_for_tuning_job`을 호출하여 튜닝 작업이 시작한 훈련 작업의 세부 목록을 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.Session().client('sagemaker')\n",
    "tuning_job_result = client.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=tuner.latest_tuning_job.job_name)\n",
    "\n",
    "status = tuning_job_result['HyperParameterTuningJobStatus']\n",
    "while status != 'Completed':\n",
    "    print('Reminder: the tuning job has not been completed.')\n",
    "    \n",
    "    job_count = tuning_job_result['TrainingJobStatusCounters']['Completed']\n",
    "    print(\"%d training jobs have completed\" % job_count)\n",
    "    \n",
    "    time.sleep(180)\n",
    "\n",
    "    tuning_job_result = client.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=tuner.latest_tuning_job.job_name)\n",
    "    status = tuning_job_result['HyperParameterTuningJobStatus']\n",
    "    \n",
    "print(\"\\n\\n All training jobs have completed\")\n",
    "is_minimize = (tuning_job_result['HyperParameterTuningJobConfig']['HyperParameterTuningJobObjective']['Type'] != 'Maximize')\n",
    "objective_name = tuning_job_result['HyperParameterTuningJobConfig']['HyperParameterTuningJobObjective']['MetricName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "if tuning_job_result.get('BestTrainingJob',None):\n",
    "    print(\"Best model found so far:\")\n",
    "    pprint(tuning_job_result['BestTrainingJob'])\n",
    "else:\n",
    "    print(\"No training jobs have reported results yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모든 결과를 DataFrame으로 가져오기\n",
    "\n",
    "모든 훈련 작업의 하이퍼파라미터 및 목표 지표를 나열하고 목표 지표가 가장 좋은 훈련 작업을 선택할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_analytics = sagemaker.HyperparameterTuningJobAnalytics(tuner.latest_tuning_job.job_name)\n",
    "\n",
    "full_df = tuner_analytics.dataframe()\n",
    "\n",
    "if len(full_df) > 0:\n",
    "    df = full_df[full_df['FinalObjectiveValue'] > -float('inf')]\n",
    "    if len(df) > 0:\n",
    "        df = df.sort_values('FinalObjectiveValue', ascending=is_minimize)\n",
    "        print(\"Number of training jobs with valid objective: %d\" % len(df))\n",
    "        print({\"lowest\":min(df['FinalObjectiveValue']),\"highest\": max(df['FinalObjectiveValue'])})\n",
    "        pd.set_option('display.max_colwidth', -1) # Don't truncate TrainingJobName        \n",
    "    else:\n",
    "        print(\"No training jobs have reported valid results yet.\")\n",
    "        \n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**질문**: 모형 튜닝이 도움이 되나요?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 답변 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 튜닝 작업 결과와 시간 비교\n",
    "\n",
    "다음으로 튜닝 작업이 진행됨에 따라 목표 지표가 시간에 따라 어떻게 변경되는지 보여줍니다. 베이지안 전략의 경우 일반적으로 결과가 개선되는 추세를 보이지만, 알고리즘이 알려진 양호한 영역의 활용과 파라미터 공간의 새로운 영역 탐색 간 균형을 맞춰야 하므로 이러한 개선 추세가 꾸준하지는 않습니다. 다음을 수행하면 검색 공간의 복잡성을 처리하기에 훈련 작업 수가 충분한지 여부를 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh\n",
    "import bokeh.io\n",
    "bokeh.io.output_notebook()\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import HoverTool\n",
    "\n",
    "class HoverHelper():\n",
    "\n",
    "    def __init__(self, tuning_analytics):\n",
    "        self.tuner = tuning_analytics\n",
    "\n",
    "    def hovertool(self):\n",
    "        tooltips = [\n",
    "            (\"FinalObjectiveValue\", \"@FinalObjectiveValue\"),\n",
    "            (\"TrainingJobName\", \"@TrainingJobName\"),\n",
    "        ]\n",
    "        for k in self.tuner.hyperparameter_ranges().keys():\n",
    "            tooltips.append( (k, \"@{%s}\" % k) )\n",
    "\n",
    "        ht = HoverTool(tooltips=tooltips)\n",
    "        return ht\n",
    "\n",
    "    def tools(self, standard_tools='pan,crosshair,wheel_zoom,zoom_in,zoom_out,undo,reset'):\n",
    "        return [self.hovertool(), standard_tools]\n",
    "\n",
    "hover = HoverHelper(tuner)\n",
    "\n",
    "p = figure(plot_width=900, plot_height=400, tools=hover.tools(), x_axis_type='datetime')\n",
    "p.circle(source=df, x='TrainingStartTime', y='FinalObjectiveValue')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 목표 지표와 개별 하이퍼파라미터 간의 상관 관계 분석\n",
    "\n",
    "튜닝 작업을 마쳤으므로 이제 목표 지표와 튜닝하도록 선택한 개별 하이퍼파라미터 간의 상관 관계를 알고 싶을 수 있습니다. 이러한 통찰력을 확보하면 특정 하이퍼파라미터의 검색 범위를 조정하고 다른 튜닝 작업을 시작하는 것이 적절한지 여부를 결정하는 데 도움이 됩니다. 예를 들어 목표 지표와 수치형 하이퍼파라미터 간에 양의 추세가 나타나는 경우 다음 튜닝 작업에서 해당 하이퍼파라미터에 대해 더 큰 튜닝 범위를 설정할 수 있습니다.\n",
    "\n",
    "다음 셀에서는 각 하이퍼파라미터에 대한 그래프를 그려 목표 지표와의 상관 관계를 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = tuner_analytics.tuning_ranges\n",
    "figures = []\n",
    "for hp_name, hp_range in ranges.items():\n",
    "    categorical_args = {}\n",
    "    if hp_range.get('Values'):\n",
    "        # 이것은 범주형으로 표시됩니다. 모든 옵션이 실제로 숫자인지 확인합니다.\n",
    "        def is_num(x):\n",
    "            try:\n",
    "                float(x)\n",
    "                return 1\n",
    "            except:\n",
    "                return 0           \n",
    "        vals = hp_range['Values']\n",
    "        if sum([is_num(x) for x in vals]) == len(vals):\n",
    "            # Bokeh는 실제로 숫자인 \"범주형\" 범위를 표시하는 데 문제가 있으므로, 숫자로 표시합니다.\n",
    "            print(\"Hyperparameter %s is tuned as categorical, but all values are numeric\" % hp_name)\n",
    "        else:\n",
    "            # 범주형 표시를 위한 추가 옵션을 설정합니다. 실제로 숫자일 때는 약간 까다롭습니다.\n",
    "            categorical_args['x_range'] = vals\n",
    "\n",
    "    # 이제 범주형 표시\n",
    "    p = figure(plot_width=600, plot_height=600, \n",
    "               title=\"Objective vs %s\" % hp_name,\n",
    "               tools=hover.tools(),\n",
    "               x_axis_label=hp_name, y_axis_label=objective_name,\n",
    "               **categorical_args)\n",
    "    p.circle(source=df, x=hp_name, y='FinalObjectiveValue')\n",
    "    figures.append(p)\n",
    "show(bokeh.layouts.Column(*figures))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이를 최종 모형로 배포하고 검정 집합에서 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model_deploy = tuner.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_batches(tuned_model_deploy, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_batches(tuned_model_deploy, val_features, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 선택 사항: XGBoost 알고리즘 사용해 보기\n",
    "훈련으로 넘어가기 전에 먼저 XGBoost 알고리즘 컨테이너의 위치를 지정해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "containers = {'us-west-2': '433757028032.dkr.ecr.us-west-2.amazonaws.com/xgboost:latest',\n",
    "              'us-east-1': '811284229777.dkr.ecr.us-east-1.amazonaws.com/xgboost:latest',\n",
    "              'us-east-2': '825641698319.dkr.ecr.us-east-2.amazonaws.com/xgboost:latest',\n",
    "              'eu-west-1': '685385470294.dkr.ecr.eu-west-1.amazonaws.com/xgboost:latest'}\n",
    "\n",
    "\n",
    "bucket = sess.default_bucket()\n",
    "prefix = 'sagemaker/xgboost-creditcard'\n",
    "\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(boto3.Session().region_name, 'xgboost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그런 다음 CSV 파일 형식으로 훈련하기 때문에 훈련 함수가 Amazon S3의 파일에 대한 포인터로 사용할 수 있는 s3_inputs를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_balanced = balanced_df.drop(['Target'], axis=1).as_matrix()\n",
    "train_labels_balanced = balanced_df['Target'].as_matrix()\n",
    "\n",
    "train_features_label = np.insert(train_features_balanced, 0, train_labels_balanced, axis=1)\n",
    "val_features_label = np.insert(val_features, 0, val_labels, axis=1)\n",
    "test_features_label = np.insert(test_features, 0, test_labels, axis=1)\n",
    "\n",
    "np.savetxt(\"train.csv\", train_features_label, delimiter=\",\")\n",
    "np.savetxt(\"validation.csv\", val_features_label, delimiter=\",\")\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation/validation.csv')).upload_file('validation.csv')\n",
    "\n",
    "s3_input_train = sagemaker.s3_input(s3_data='s3://{}/{}/train'.format(bucket, prefix), content_type='csv')\n",
    "s3_input_validation = sagemaker.s3_input(s3_data='s3://{}/{}/validation/'.format(bucket, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 사용할 훈련 인스턴스의 유형과 개수 등 몇 가지 파라미터와 XGBoost 하이퍼파라미터를 지정할 수 있습니다. 몇 가지 주요 하이퍼파라미터는 다음과 같습니다.\n",
    "\n",
    "– `max_depth`: 알고리즘 내 각 트리의 깊이를 제어합니다. 더 깊은 트리는 적합성이 향상될 수 있지만 계산 비용이 더 많이 들고 과대적합으로 이어질 수 있습니다. 모형 성능에는 일반적으로 많은 수의 얕은 트리와 더 적은 수의 더 깊은 트리 사이에서 탐구해야 하는 절충점이 있습니다.\n",
    "- `subsample`: 훈련 데이터의 표집을 제어합니다. 이 기법은 과대적합을 줄이는 데 도움이 되지만, 너무 낮게 설정하면 데이터 모형을 사용하지 못할 수도 있습니다.\n",
    "- `num_round`: 부스팅 라운드 수를 제어합니다. 이는 기본적으로 이전 반복의 잔차를 사용하여 훈련된 후속 모형입니다. 다시 말하지만 라운드가 많을수록 훈련 데이터에 더 적합하지만 계산 비용이 많이 들거나 과대적합으로 이어질 수 있습니다.\n",
    "- `eta`: 부스팅의 각 라운드가 얼마나 공격적인지 제어합니다. 값이 클수록 부스팅이 더 보수적이 됩니다.\n",
    "- `gamma`: 트리가 얼마나 공격적으로 커지는지를 제어합니다. 값이 클수록 모형이 더 보수적이 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    train_instance_count=1, \n",
    "                                    train_instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                    sagemaker_session=sess)\n",
    "xgb.set_hyperparameters(max_depth=10,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=1,\n",
    "                        subsample=0.8,\n",
    "                        silent=0,\n",
    "                        objective='binary:logistic',\n",
    "                        eval_metric='auc',\n",
    "                        num_round=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 추정기에 대한 훈련 파라미터를 지정해야 합니다. 설정에는 다음이 포함됩니다.\n",
    "\n",
    "- XGBoost 알고리즘 컨테이너\n",
    "- 사용할 IAM 역할\n",
    "- 훈련 인스턴스 유형 및 개수\n",
    "- 출력 데이터를 위한 Amazon S3 위치\n",
    "-  알고리즘 하이퍼파라미터\n",
    "\n",
    "그런 다음 출력 데이터의 Amazon S3 위치를 지정하는 `.fit()` 함수를 설정합니다. 이 경우 훈련 집합과 검증 집합이 모두 전달됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 호스팅\n",
    "\n",
    "데이터로 XGBoost 알고리즘을 훈련했으므로 이제 실시간 엔드포인트 뒤에서 호스팅되는 모형을 배포합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker에 모형을 배포합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor = # 여기에 코드 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import csv_serializer \n",
    "\n",
    "def predict_xgboost(model, data, labels, rows=500):\n",
    "    \n",
    "    model.content_type = 'text/csv'\n",
    "    model.serializer = csv_serializer\n",
    "    model.deserializer = None\n",
    "    \n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = ''\n",
    "    for array in split_array:\n",
    "        predictions = ','.join([predictions, model.predict(array).decode('utf-8')])\n",
    "        \n",
    "    preds = np.fromstring(predictions[1:], sep=',')\n",
    "    confusion_matrix = pd.crosstab(index=labels, columns=np.round(preds), rownames=['True'], colnames=['predictions']).astype(int)\n",
    "    plt.figure(figsize = (5,5))\n",
    "    sns.heatmap(confusion_matrix, annot=True, fmt='.2f', cmap=\"YlGnBu\").set_title('Confusion Matrix') \n",
    "\n",
    "predict_xgboost(xgb_predictor, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "hyperparameter_ranges_xgb = {'eta': ContinuousParameter(0.01, 0.2),\n",
    "                         'max_depth': IntegerParameter(3, 9),\n",
    "                         'gamma': IntegerParameter(0, 5),\n",
    "                         'min_child_weight': IntegerParameter(2, 6),\n",
    "                         'subsample': ContinuousParameter(0.5, 0.9),\n",
    "                         'colsample_bytree': ContinuousParameter(0.5, 0.9)}\n",
    "\n",
    "objective_metric_name_xgb = 'validation:auc'\n",
    "\n",
    "tuner_xgb = HyperparameterTuner(xgb,\n",
    "                            objective_metric_name_xgb,\n",
    "                            hyperparameter_ranges_xgb,\n",
    "                            max_jobs=10,\n",
    "                            max_parallel_jobs=1)\n",
    "\n",
    "tuner_xgb.fit({'train': s3_input_train, 'validation': s3_input_validation}, include_cls_metadata=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.Session().client('sagemaker')\n",
    "tuning_job_result = client.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=tuner_xgb.latest_tuning_job.job_name)\n",
    "\n",
    "status = tuning_job_result['HyperParameterTuningJobStatus']\n",
    "while status != 'Completed':\n",
    "    print('Reminder: the tuning job has not been completed.')\n",
    "    \n",
    "    job_count = tuning_job_result['TrainingJobStatusCounters']['Completed']\n",
    "    print(\"%d training jobs have completed\" % job_count)\n",
    "    \n",
    "    time.sleep(180)\n",
    "\n",
    "    tuning_job_result = client.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=tuner_xgb.latest_tuning_job.job_name)\n",
    "    status = tuning_job_result['HyperParameterTuningJobStatus']\n",
    "    \n",
    "print(\"Training jobs have completed\")\n",
    "is_minimize = (tuning_job_result['HyperParameterTuningJobConfig']['HyperParameterTuningJobObjective']['Type'] != 'Maximize')\n",
    "objective_name = tuning_job_result['HyperParameterTuningJobConfig']['HyperParameterTuningJobObjective']['MetricName']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker에 튜닝된 모형을 배포합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor_tuned = tuner_xgb.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_xgboost(xgb_predictor_tuned, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결론\n",
    "\n",
    "이제 모형을 훈련하고 평가하는 과정을 최소한 두 번 반복했습니다. 이제 이 프로젝트를 마무리하고 학습한 내용과 앞으로 수행할 단계에 대해 생각해 볼 차례입니다(시간 여유가 있다고 가정할 때). 아래 셀을 사용하여 이러한 질문 및 기타 관련 질문에 답합니다.\n",
    "\n",
    "1. 모형 성능이 비즈니스 목표에 부합하나요? 그렇지 않은 경우 튜닝할 시간이 더 있었다면 어떻게 다르게 할 수 있을까요?\n",
    "2. 데이터 집합, 특성 및 하이퍼파라미터를 변경함에 따라 모형이 어느 정도 향상되었나요? 이 프로젝트 전체에서 모형을 가장 크게 개선한 것으로 생각되는 기법은 무엇인가요?\n",
    "3. 이 프로젝트를 통틀어 가장 어려움을 겪었던 문제에는 어떤 것들이 있나요?\n",
    "4. 파이프라인에서 여러분이 이해할 수 없었던 부분 중 해결되지 않은 질문이 있나요?\n",
    "5. 이 프로젝트를 진행하면서 기계 학습에 대해 배운 가장 중요한 세 가지는 무엇인가요?\n",
    "\n",
    "### <span style=\"color: blue;\">프로젝트 프레젠테이션: 이러한 질문에 대한 답변을 요약하여 프로젝트 프레젠테이션에도 추가합니다. 이제 프로젝트 프레젠테이션을 위한 모든 노트를 취합하여 학급을 대상으로 발표할 준비를 합니다.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
